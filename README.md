# Pipeline de Resumen Extractivo Avanzado

Un sistema modular de resumen extractivo multilingÃ¼e que implementa algoritmos avanzados de procesamiento de lenguaje natural usando scikit-learn. DiseÃ±ado para ser eficiente, extensible y con dependencias mÃ­nimas.

## ğŸ—ï¸ **Arquitectura del Sistema**

### **MÃ³dulos Principales y su Funcionamiento**

```
summarization_pipeline/
â”œâ”€â”€ ğŸ“ text_preprocessor.py    # Procesamiento y limpieza de texto
â”œâ”€â”€ ğŸ“ semantic_summarizer.py  # Algoritmo principal de resumen
â”œâ”€â”€ ğŸ“ metrics_evaluator.py    # EvaluaciÃ³n y mÃ©tricas de calidad
â”œâ”€â”€ ğŸ“ main.py                 # Ejemplos y uso principal
â””â”€â”€ ğŸ“ __init__.py            # ConfiguraciÃ³n del paquete
```

#### **1. ğŸ“ text_preprocessor.py - Procesamiento Inteligente de Texto**

**PropÃ³sito**: Preparar y limpiar el texto para el anÃ¡lisis semÃ¡ntico.

**Flujo de procesamiento**:
```
texto_entrante â†’ detect_language() â†’ split_sentences() â†’ preprocess_text() â†’ datos_estructurados
```

**TÃ©cnicas Implementadas**:

- **ğŸ”¤ DetecciÃ³n de Idioma Mejorada**:
  Combina mÃºltiples heurÃ­sticas: caracteres especiales (Ã¡, Ã©, Ã­, Ã³, Ãº, Ã±), palabras comunes por idioma, y longitud promedio de palabras para determinar si el texto es espaÃ±ol o inglÃ©s.

- **ğŸ“ DivisiÃ³n de Oraciones con NLTK**:
  Utiliza tokenizaciÃ³n inteligente de NLTK para dividir el texto en oraciones, filtrando aquellas muy cortas (<20 caracteres) que suelen contener poca informaciÃ³n.

- **ğŸ” ExtracciÃ³n de Frases Clave**:
  Identifica n-gramas importantes (1-3 palabras) usando TF-IDF. Ejemplo: `[("aprendizaje automÃ¡tico", 0.85), ("inteligencia artificial", 0.78)]`

- **ğŸ§¹ Preprocesamiento de Texto**:
  Convierte a minÃºsculas, elimina puntuaciÃ³n, remueve stopwords y filtra palabras muy cortas para limpiar el texto manteniendo el contexto semÃ¡ntico.

**Salida**: Diccionario estructurado con metadatos del texto procesado, incluyendo oraciones originales, oraciones preprocesadas, frases clave y puntuaciones semÃ¡nticas.

---

#### **2. ğŸ“ semantic_summarizer.py - Algoritmo Principal de Resumen**

**PropÃ³sito**: Seleccionar las oraciones mÃ¡s importantes usando TF-ICF mejorado y clustering semÃ¡ntico.

**TÃ©cnicas Implementadas**:

- **ğŸ¯ TF-ICF Mejorado (Term Frequency - Inverse Class Frequency)**:
  ```python
  # FÃ³rmula mejorada:
  TF(tÃ©rmino) = (frecuencia en oraciÃ³n) / (total tÃ©rminos) * peso_longitud
  ICF(tÃ©rmino) = log(total_oraciones / docs_con_tÃ©rmino) + ajuste
  Score = Î£ [TF(t) Ã— ICF(t)] para cada tÃ©rmino t
  ```
  El TF-ICF identifica tÃ©rminos que son importantes dentro de una oraciÃ³n pero poco comunes en otras oraciones del mismo texto.

- **ğŸ“Š Sistema de Scoring Multi-dimensional**:
  Combina mÃºltiples factores con pesos optimizados:
  - 35% TF-ICF (relevancia lÃ©xica)
  - 30% Frases clave del documento
  - 20% AnÃ¡lisis semÃ¡ntico del preprocesador
  - 15% PosiciÃ³n estratÃ©gica (curva en U)

- **ğŸª Clustering SemÃ¡ntico Adaptativo**:
  Agrupa oraciones similares temÃ¡ticamente usando K-means sobre representaciones TF-IDF, asegurando diversidad en el resumen final.

- **ğŸ”„ Estrategia de SelecciÃ³n en 3 Fases**:
  1. **Mejor por cluster** - Garantiza diversidad temÃ¡tica
  2. **Segunda mejor de clusters grandes** - AÃ±ade profundidad
  3. **Mejores globales restantes** - Asegura mÃ¡xima relevancia

**Salida**: Resumen estructurado con mÃ©tricas de compresiÃ³n, oraciones seleccionadas y datos para evaluaciÃ³n.

---

#### **3. ğŸ“ metrics_evaluator.py - EvaluaciÃ³n de Calidad**

**PropÃ³sito**: Medir la calidad del resumen usando mÃ©tricas estandarizadas.

**MÃ©tricas Implementadas**:

- **ğŸ“ˆ ROUGE-like Score**: Mide cobertura de contenido comparando la superposiciÃ³n de palabras entre el resumen y el original.

- **ğŸ”¤ BLEU Score Mejorado**: EvalÃºa similitud n-gram con referencias mÃºltiples usando smoothing para evitar zeros.

- **ğŸ”„ Coherencia**: Calcula la fluidez entre oraciones del resumen usando similitud de coseno entre representaciones vectoriales consecutivas.

- **ğŸ¯ Cobertura SemÃ¡ntica**: Porcentaje de frases clave del documento original que estÃ¡n incluidas en el resumen.

- **ğŸ“Š Score General Ponderado**: Combina todas las mÃ©tricas con pesos optimizados para un evaluaciÃ³n integral.

---

## ğŸš€ **Uso del Pipeline en tus Programas Python**

### **1. Uso BÃ¡sico - Resumen Simple**

```python
from sklearn.pipeline import Pipeline
from text_preprocessor import EnhancedTextPreprocessor
from semantic_summarizer import SemanticTFICFSummarizer

# Crear pipeline
pipeline = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor()),
    ('summarizer', SemanticTFICFSummarizer(n_sentences=3))
])

# Texto a resumir
texto_largo = "Tu texto largo aquÃ­..."

# Generar resumen
resultados = pipeline.fit_transform([texto_largo])
resumen = resultados[0]['summary']

print(f"ğŸ“ Resumen: {resumen}")
print(f"ğŸ“Š CompresiÃ³n: {resultados[0]['compression_ratio']:.1%}")
print(f"ğŸ”¤ Idioma: {resultados[0]['language']}")
```

### **2. Uso Avanzado - Con EvaluaciÃ³n de Calidad**

```python
from metrics_evaluator import AdvancedSummaryEvaluator

# Pipeline con configuraciÃ³n avanzada
pipeline_avanzado = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor(
        min_word_length=3,
        use_semantic_analysis=True
    )),
    ('summarizer', SemanticTFICFSummarizer(
        n_sentences='auto',           # CÃ¡lculo automÃ¡tico
        clustering_method='kmeans',   # Clustering semÃ¡ntico
        diversity_weight=0.4          # Ã‰nfasis en diversidad
    ))
])

# Procesar y evaluar
resultados = pipeline_avanzado.fit_transform([texto_largo])
evaluator = AdvancedSummaryEvaluator()

evaluacion = evaluator.comprehensive_evaluation(
    texto_largo,
    resultados[0]['summary'],
    "Mi Resumen",
    resultados[0],
    resultados[0]['selected_sentences']
)

print(f"ğŸ¯ Score General: {evaluacion['metrics']['overall_score']:.3f}")
print(f"ğŸ“ˆ ROUGE: {evaluacion['metrics']['rouge_like_score']:.3f}")
print(f"ğŸ”¤ BLEU: {evaluacion['metrics']['bleu_score']:.3f}")
```

### **3. PersonalizaciÃ³n para Dominios EspecÃ­ficos**

```python
class MedicalSummarizer(SemanticTFICFSummarizer):
    """Summarizer especializado en textos mÃ©dicos"""
    
    def __init__(self, n_sentences='auto'):
        super().__init__(n_sentences)
        self.medical_terms = {
            'diagnÃ³stico', 'tratamiento', 'sÃ­ntomas', 'paciente', 
            'enfermedad', 'medicamento', 'hospital', 'cÃ¡ncer'
        }
    
    def calculate_semantic_scores(self, processed_data):
        scores = super().calculate_semantic_scores(processed_data)
        
        # Bonus para tÃ©rminos mÃ©dicos
        for i, (idx, score, length) in enumerate(scores):
            sentence = processed_data['sentences'][idx].lower()
            medical_bonus = sum(1 for term in self.medical_terms if term in sentence)
            medical_bonus = min(medical_bonus * 0.15, 0.3)
            scores[i] = (idx, score * (1 + medical_bonus), length)
        
        return scores

# Pipeline mÃ©dico especializado
pipeline_medico = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor()),
    ('summarizer', MedicalSummarizer(n_sentences=4))
])
```

### **4. Procesamiento por Lotes**

```python
import pandas as pd

# Procesar mÃºltiples documentos
documentos = [texto1, texto2, texto3, texto4]
resultados = pipeline.fit_transform(documentos)

# Crear DataFrame con resultados
df_resultados = pd.DataFrame([{
    'resumen': r['summary'],
    'compresion': r['compression_ratio'],
    'idioma': r['language'],
    'oraciones_seleccionadas': len(r['selected_sentences'])
} for r in resultados])

df_resultados.to_csv('resumenes_generados.csv', index=False)
```

## ğŸ“Š **MÃ©tricas de EvaluaciÃ³n**

| MÃ©trica | DescripciÃ³n | Rango Ã“ptimo | InterpretaciÃ³n |
|---------|-------------|--------------|----------------|
| **ROUGE-like** | Cobertura de contenido | 0.4-0.7 | Mide quÃ© tan bien el resumen representa el contenido original |
| **BLEU Score** | Similitud lexical | 0.3-0.6 | EvalÃºa la similitud en tÃ©rminos especÃ­ficos con el original |
| **Coherencia** | Fluidez del resumen | 0.6-1.0 | Indica quÃ© tan bien fluyen las oraciones entre sÃ­ |
| **Cobertura** | Frases clave incluidas | 0.7-1.0 | Porcentaje de conceptos importantes capturados |
| **Diversidad** | Variedad lexical | 0.7-0.9 | Mide la riqueza vocabular del resumen |
| **Redundancia** | RepeticiÃ³n de tÃ©rminos | 0.0-0.2 | Menos es mejor - indica repeticiÃ³n excesiva |

## ğŸ¯ **TÃ©cnicas de IA Implementadas**

### **TF-ICF (Term Frequency - Inverse Class Frequency)**
Variante especializada de TF-IDF para resumen de documentos individuales. Trata cada oraciÃ³n como una "clase" y calcula la importancia de tÃ©rminos basÃ¡ndose en su distribuciÃ³n entre oraciones.

### **Clustering SemÃ¡ntico con K-means**
Agrupa oraciones similares usando representaciones vectoriales TF-IDF, permitiendo seleccionar oraciones diversas que cubran diferentes temas del documento.

### **AnÃ¡lisis de Frases Clave**
Identifica n-gramas importantes usando TF-IDF a nivel de documento completo, dando mayor peso a oraciones que contienen estos conceptos centrales.

### **Scoring Multi-dimensional**
Combina mÃºltiples seÃ±ales (posiciÃ³n, longitud, relevancia lÃ©xica, frases clave) con pesos aprendidos empÃ­ricamente para una selecciÃ³n balanceada.

## âš¡ **Rendimiento y OptimizaciÃ³n**

- **Procesamiento CPU**: Optimizado para funcionar sin GPUs
- **Dependencias mÃ­nimas**: Solo scikit-learn, numpy y NLTK bÃ¡sico
- **Escalabilidad**: Maneja documentos de 100 a 10,000 palabras
- **Tiempos de procesamiento**: ~1-5 segundos para documentos tÃ­picos

## ğŸ”§ **Configuraciones Recomendadas**

### **Para Noticias/ArtÃ­culos**
```python
pipeline_noticias = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor(min_word_length=2)),
    ('summarizer', SemanticTFICFSummarizer(n_sentences=3))
])
```

### **Para Documentos TÃ©cnicos**
```python
pipeline_tecnico = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor(min_word_length=4)),
    ('summarizer', SemanticTFICFSummarizer(n_sentences=4, diversity_weight=0.5))
])
```

### **Para Textos Muy Largos**
```python
pipeline_largo = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor()),
    ('summarizer', SemanticTFICFSummarizer(n_sentences='auto'))
])
```

## ğŸ“ˆ **Resultados Esperados**

Con textos bien estructurados, el sistema tÃ­picamente produce:
- **CompresiÃ³n**: 20-30% del texto original
- **ROUGE Score**: 0.4-0.6
- **BLEU Score**: 0.3-0.5
- **Coherencia**: 0.6-0.8

## ğŸš¨ **Limitaciones y Consideraciones**

- Funciona mejor con textos bien estructurados y pÃ¡rrafos coherentes
- El rendimiento puede variar con textos muy tÃ©cnicos o especializados
- La detecciÃ³n de idioma asume textos mayoritariamente en un idioma
- Optimizado para espaÃ±ol e inglÃ©s, otros idiomas requieren ajustes

## ğŸ¤ **Contribuciones**

Las contribuciones son bienvenidas en Ã¡reas como:

- Soporte para mÃ¡s idiomas
- Mejoras en la detecciÃ³n de idioma
- Optimizaciones de rendimiento
- Nuevas mÃ©tricas de evaluaciÃ³n

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT.