# Pipeline de Resumen

Un sistema de resumen extractivo multiling√ºe implementado como pipeline de scikit-learn que utiliza el algoritmo TF-ICF (Term Frequency - Inverse Class Frequency) para identificar las oraciones m√°s importantes de un texto.

## üöÄ Caracter√≠sticas

- **Resumen extractivo** basado en importancia sem√°ntica
- **Soporte multiling√ºe** (espa√±ol e ingl√©s) con detecci√≥n autom√°tica
- **Algoritmo TF-ICF** adaptado para resumen de documentos individuales
- **Pipeline modular** de scikit-learn f√°cil de extender
- **Preprocesamiento inteligente** con limpieza de texto y stopwords
- **M√≠nimas dependencias** - solo scikit-learn y numpy

## üìã Requisitos

```bash
pip install scikit-learn numpy
```

## üß† Algoritmo TF-ICF

### Fundamentos Te√≥ricos

El TF-ICF (Term Frequency - Inverse Class Frequency) es una variante del TF-IDF adaptada para tareas de clasificaci√≥n y resumen:

- **TF (Term Frequency)**: Frecuencia normalizada de t√©rminos dentro de una oraci√≥n
- **ICF (Inverse Class Frequency)**: Medida de qu√© tan √∫nico es un t√©rmino entre las "clases" (en este caso, oraciones)

### F√≥rmula Matem√°tica

```
TF(t, s) = (N√∫mero de veces que t aparece en s) / (N√∫mero total de t√©rminos en s)
ICF(t) = log(Total de oraciones / N√∫mero de oraciones que contienen t)
Puntaje(s) = Œ£ [TF(t, s) √ó ICF(t)] para cada t√©rmino t en s
```

### Ventajas sobre TF-IDF

- **Mejor para documentos individuales**: TF-ICF trata cada oraci√≥n como una "clase"
- **Identifica t√©rminos discriminativos**: Prioriza palabras que distinguen entre oraciones
- **√ìptimo para resumen**: Selecciona oraciones con informaci√≥n √∫nica y relevante

## üõ†Ô∏è Uso B√°sico

### Ejemplo Simple

```python
from summarization_pipeline import summarization_pipeline

# Texto a resumir
texto = """
El aprendizaje autom√°tico es una rama de la inteligencia artificial. 
Los algoritmos de machine learning permiten a las computadoras aprender patrones en los datos. 
En la actualidad, el deep learning ha revolucionado muchas √°reas. 
Espa√±a es un pa√≠s con gran desarrollo en tecnolog√≠a. 
Los investigadores espa√±oles contribuyen significativamente al campo.
"""

# Procesar y obtener resumen
resultados = summarization_pipeline.fit_transform([texto])
resumen = resultados[0]['summary']

print("Resumen:", resumen)
```

### Uso con M√∫ltiples Textos

```python
textos = [
    "Texto en espa√±ol sobre machine learning...",
    "English text about artificial intelligence...",
    "Otro texto en espa√±ol sobre deep learning..."
]

resultados = summarization_pipeline.fit_transform(textos)

for i, resultado in enumerate(resultados):
    print(f"Texto {i+1} ({resultado['language']}):")
    print(f"Resumen: {resultado['summary']}")
    print(f"Oraciones seleccionadas: {resultado['selected_sentences']}\n")
```

## üìÅ Estructura del Pipeline

### TextPreprocessor

**Responsabilidades:**
- Detecci√≥n autom√°tica de idioma
- Divisi√≥n en oraciones
- Limpieza y normalizaci√≥n de texto
- Eliminaci√≥n de stopwords

**Flujo de procesamiento:**
1. `detect_language()`: Identifica espa√±ol/ingl√©s por caracteres especiales
2. `split_sentences()`: Divide en oraciones usando regex
3. `preprocess_text()`: Limpia, tokeniza y filtra stopwords

### TFICFSummarizer

**Responsabilidades:**
- C√°lculo de scores TF-ICF
- Selecci√≥n de oraciones relevantes
- Generaci√≥n del resumen final

**Flujo de c√°lculo:**
1. `calculate_tf()`: Frecuencia de t√©rminos normalizada por oraci√≥n
2. `calculate_icf()`: Frecuencia inversa entre oraciones
3. `calculate_sentence_scores()`: Combina TF e ICF para puntuar oraciones
4. Selecciona top-N oraciones manteniendo orden original

## ‚öôÔ∏è Personalizaci√≥n

### Modificar N√∫mero de Oraciones

```python
pipeline_personalizado = Pipeline([
    ('preprocessor', TextPreprocessor()),
    ('summarizer', TFICFSummarizer(n_sentences=3))  # 3 oraciones en el resumen
])
```

### Agregar Stopwords Personalizadas

```python
class TextPreprocessorPersonalizado(TextPreprocessor):
    def __init__(self):
        super().__init__()
        # Agregar stopwords personalizadas
        self.stopwords_es.update({'python', 'c√≥digo', 'programaci√≥n'})
        self.stopwords_en.update({'python', 'code', 'programming'})
```

### Pipeline para Dominio Espec√≠fico

```python
class DomainSpecificSummarizer(TFICFSummarizer):
    def __init__(self, n_sentences=2, domain_terms=None):
        super().__init__(n_sentences)
        self.domain_terms = domain_terms or {}
    
    def calculate_sentence_scores(self, processed_data):
        scores = super().calculate_sentence_scores(processed_data)
        # Bonus para t√©rminos del dominio
        for i, (idx, score, length) in enumerate(scores):
            domain_bonus = self._calculate_domain_bonus(processed_data['processed_sentences'][idx])
            scores[i] = (idx, score * (1 + domain_bonus), length)
        return scores
    
    def _calculate_domain_bonus(self, sentence):
        # Implementar l√≥gica de bonus para t√©rminos del dominio
        pass
```

## üìä Ejemplos Completos

### Ejemplo 1: Texto Cient√≠fico

```python
texto_cientifico = """
La inteligencia artificial est√° transformando la investigaci√≥n cient√≠fica. 
Los modelos de deep learning pueden predecir estructuras proteicas con alta precisi√≥n. 
Estos avances aceleran el desarrollo de nuevos medicamentos. 
Sin embargo, existen desaf√≠os √©ticos en el uso de IA en medicina. 
La interpretabilidad de los modelos sigue siendo un problema importante.
"""

resultado = summarization_pipeline.fit_transform([texto_cientifico])[0]
print(f"Idioma: {resultado['language']}")
print(f"Resumen: {resultado['summary']}")
print(f"Oraciones seleccionadas: {resultado['selected_sentences']}")
```

### Ejemplo 2: Texto Period√≠stico

```python
texto_noticia = """
El cambio clim√°tico afecta gravemente a los ecosistemas marinos. 
Las temperaturas oce√°nicas han aumentado significativamente en la √∫ltima d√©cada. 
Esto provoca la decoloraci√≥n de los arrecifes de coral en todo el mundo. 
Los cient√≠ficos advierten sobre consecuencias irreversibles si no se toman medidas. 
Varios pa√≠ses han firmado acuerdos para reducir las emisiones de carbono.
"""

resultado = summarization_pipeline.fit_transform([texto_noticia])[0]
```

## üß™ Testing y Validaci√≥n

### Ejecutar Ejemplos de Prueba

```bash
python summarization_pipeline.py
```

### Output Esperado

```
--- Texto 1 (ES) ---
Original:
    El aprendizaje autom√°tico es una rama de la inteligencia artificial. 
    Los algoritmos de machine...

Resumen:
Los algoritmos de machine learning permiten a las computadoras aprender patrones en los datos. En la actualidad, el deep learning ha revolucionado muchas √°reas.
Oraciones seleccionadas: [1, 2]
--------------------------------------------------
```

## üîß Extensi√≥n del Sistema

### Agregar Nuevos Idiomas

```python
class MultilingualTextPreprocessor(TextPreprocessor):
    def __init__(self):
        super().__init__()
        self.stopwords_fr = {'le', 'la', 'de', 'et', '√†'}  # Franc√©s
        self.stopwords_pt = {'o', 'a', 'de', 'e', 'em'}   # Portugu√©s
    
    def detect_language(self, text):
        # Implementar detecci√≥n m√°s sofisticada
        if re.search(r'[√°√©√≠√≥√∫√±]', text):
            return 'es'
        elif re.search(r'[√†√¢√™√Æ√¥√ª]', text):
            return 'fr'
        else:
            return 'en'
```

### Integraci√≥n con APIs Externas

```python
class APISummarizer(TFICFSummarizer):
    def __init__(self, n_sentences=2, api_key=None):
        super().__init__(n_sentences)
        self.api_key = api_key
    
    def transform(self, X):
        resultados = super().transform(X)
        # Enriquecer resultados con API externa
        for resultado in resultados:
            resultado['entities'] = self._extract_entities(resultado['summary'])
        return resultados
```

## üìà M√©tricas y Evaluaci√≥n

### Evaluaci√≥n de Calidad

```python
def evaluate_summary_quality(original, summary, reference_summary=None):
    """Eval√∫a la calidad del resumen usando m√©tricas simples"""
    
    # M√©tricas b√°sicas
    compression_ratio = len(summary) / len(original)
    sentence_reduction = 1 - (summary.count('.') / original.count('.'))
    
    metrics = {
        'compression_ratio': compression_ratio,
        'sentence_reduction': sentence_reduction,
        'summary_length': len(summary),
        'original_length': len(original)
    }
    
    return metrics
```

## üêõ Soluci√≥n de Problemas

### Problemas Comunes

1. **Oraciones vac√≠as en el resumen**
   - Causa: Preprocesamiento muy agresivo
   - Soluci√≥n: Ajustar umbral de stopwords o longitud m√≠nima

2. **Detecci√≥n incorrecta de idioma**
   - Causa: Textos mixtos o sin caracteres especiales
   - Soluci√≥n: Implementar detecci√≥n m√°s robusta

3. **Resumen muy corto/largo**
   - Causa: Par√°metro n_sentences inadecuado
   - Soluci√≥n: Ajustar din√°micamente seg√∫n longitud del texto

## ü§ù Contribuciones

Las contribuciones son bienvenidas. √Åreas de mejora:

- [ ] Soporte para m√°s idiomas
- [ ] Detecci√≥n de idioma m√°s robusta
- [ ] Integraci√≥n con modelos transformer
- [ ] Evaluaci√≥n autom√°tica de calidad
- [ ] Interfaz web o API REST

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo LICENSE para m√°s detalles.

