# Pipeline de Resumen Extractivo Avanzado

Un sistema modular de resumen extractivo multilingÃ¼e que implementa algoritmos avanzados de procesamiento de lenguaje natural usando scikit-learn. DiseÃ±ado para ser eficiente, extensible y con dependencias mÃ­nimas.

## ğŸ—ï¸ **Arquitectura del Sistema**

### **MÃ³dulos Principales y su Funcionamiento**

```
summarization_pipeline/
â”œâ”€â”€ ğŸ“ text_preprocessor.py    # Procesamiento y limpieza de texto
â”œâ”€â”€ ğŸ“ semantic_summarizer.py  # Algoritmo principal de resumen
â”œâ”€â”€ ğŸ“ metrics_evaluator.py    # EvaluaciÃ³n y mÃ©tricas de calidad
â”œâ”€â”€ ğŸ“ main.py                 # Ejemplos y uso principal
â””â”€â”€ ğŸ“ __init__.py            # ConfiguraciÃ³n del paquete
```

#### **1. ğŸ“ text_preprocessor.py - Procesamiento Inteligente de Texto**

**PropÃ³sito**: Preparar y limpiar el texto para el anÃ¡lisis semÃ¡ntico.

**Flujo de procesamiento**:
```
texto_entrante â†’ detect_language() â†’ split_sentences() â†’ preprocess_text() â†’ datos_estructurados
```

**TÃ©cnicas Implementadas**:

- **ğŸ”¤ DetecciÃ³n de Idioma Mejorada**:
  Combina mÃºltiples heurÃ­sticas: caracteres especiales (Ã¡, Ã©, Ã­, Ã³, Ãº, Ã±), palabras comunes por idioma, y longitud promedio de palabras para determinar si el texto es espaÃ±ol o inglÃ©s.

- **ğŸ“ DivisiÃ³n de Oraciones con NLTK**:
  Utiliza tokenizaciÃ³n inteligente de NLTK para dividir el texto en oraciones, filtrando aquellas muy cortas (<20 caracteres) que suelen contener poca informaciÃ³n.

- **ğŸ” ExtracciÃ³n de Frases Clave**:
  Identifica n-gramas importantes (1-3 palabras) usando TF-IDF. Ejemplo: `[("aprendizaje automÃ¡tico", 0.85), ("inteligencia artificial", 0.78)]`

- **ğŸ§¹ Preprocesamiento de Texto**:
  Convierte a minÃºsculas, elimina puntuaciÃ³n, remueve stopwords y filtra palabras muy cortas para limpiar el texto manteniendo el contexto semÃ¡ntico.

**Salida**: Diccionario estructurado con metadatos del texto procesado, incluyendo oraciones originales, oraciones preprocesadas, frases clave y puntuaciones semÃ¡nticas.

---

#### **2. ğŸ“ semantic_summarizer.py - Algoritmo Principal de Resumen**

**PropÃ³sito**: Seleccionar las oraciones mÃ¡s importantes usando TF-ICF mejorado y clustering semÃ¡ntico.

**TÃ©cnicas Implementadas**:

- **ğŸ¯ TF-ICF Mejorado (Term Frequency - Inverse Class Frequency)**:
  ```python
  # FÃ³rmula mejorada:
  TF(tÃ©rmino) = (frecuencia en oraciÃ³n) / (total tÃ©rminos) * peso_longitud
  ICF(tÃ©rmino) = log(total_oraciones / docs_con_tÃ©rmino) + ajuste
  Score = Î£ [TF(t) Ã— ICF(t)] para cada tÃ©rmino t
  ```
  El TF-ICF identifica tÃ©rminos que son importantes dentro de una oraciÃ³n pero poco comunes en otras oraciones del mismo texto.

- **ğŸ“Š Sistema de Scoring Multi-dimensional**:
  Combina mÃºltiples factores con pesos optimizados:
  - 35% TF-ICF (relevancia lÃ©xica)
  - 30% Frases clave del documento
  - 20% AnÃ¡lisis semÃ¡ntico del preprocesador
  - 15% PosiciÃ³n estratÃ©gica (curva en U)

- **ğŸª Clustering SemÃ¡ntico Adaptativo**:
  Agrupa oraciones similares temÃ¡ticamente usando K-means sobre representaciones TF-IDF, asegurando diversidad en el resumen final.

- **ğŸ”„ Estrategia de SelecciÃ³n en 3 Fases**:
  1. **Mejor por cluster** - Garantiza diversidad temÃ¡tica
  2. **Segunda mejor de clusters grandes** - AÃ±ade profundidad
  3. **Mejores globales restantes** - Asegura mÃ¡xima relevancia

**Salida**: Resumen estructurado con mÃ©tricas de compresiÃ³n, oraciones seleccionadas y datos para evaluaciÃ³n.

---

#### **3. ğŸ“ metrics_evaluator.py - EvaluaciÃ³n de Calidad**

**PropÃ³sito**: Medir la calidad del resumen usando mÃ©tricas estandarizadas.

**MÃ©tricas Implementadas**:

- **ğŸ“ˆ ROUGE-like Score**: Mide cobertura de contenido comparando la superposiciÃ³n de palabras entre el resumen y el original.

- **ğŸ”¤ BLEU Score Mejorado**: EvalÃºa similitud n-gram con referencias mÃºltiples usando smoothing para evitar zeros.

- **ğŸ”„ Coherencia**: Calcula la fluidez entre oraciones del resumen usando similitud de coseno entre representaciones vectoriales consecutivas.

- **ğŸ¯ Cobertura SemÃ¡ntica**: Porcentaje de frases clave del documento original que estÃ¡n incluidas en el resumen.

- **ğŸ“Š Score General Ponderado**: Combina todas las mÃ©tricas con pesos optimizados para un evaluaciÃ³n integral.

---

## ğŸš€ **Uso del Pipeline en tus Programas Python**

### **1. Uso BÃ¡sico - Resumen Simple**

```python
from sklearn.pipeline import Pipeline
from text_preprocessor import EnhancedTextPreprocessor
from semantic_summarizer import SemanticTFICFSummarizer

# Crear pipeline
pipeline = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor()),
    ('summarizer', SemanticTFICFSummarizer(n_sentences=3))
])

# Texto a resumir
texto_largo = "Tu texto largo aquÃ­..."

# Generar resumen
resultados = pipeline.fit_transform([texto_largo])
resumen = resultados[0]['summary']

print(f"ğŸ“ Resumen: {resumen}")
print(f"ğŸ“Š CompresiÃ³n: {resultados[0]['compression_ratio']:.1%}")
print(f"ğŸ”¤ Idioma: {resultados[0]['language']}")
```

### **2. Uso Avanzado - Con EvaluaciÃ³n de Calidad**

```python
from metrics_evaluator import AdvancedSummaryEvaluator

# Pipeline con configuraciÃ³n avanzada
pipeline_avanzado = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor(
        min_word_length=3,
        use_semantic_analysis=True
    )),
    ('summarizer', SemanticTFICFSummarizer(
        n_sentences='auto',           # CÃ¡lculo automÃ¡tico
        clustering_method='kmeans',   # Clustering semÃ¡ntico
        diversity_weight=0.4          # Ã‰nfasis en diversidad
    ))
])

# Procesar y evaluar
resultados = pipeline_avanzado.fit_transform([texto_largo])
evaluator = AdvancedSummaryEvaluator()

evaluacion = evaluator.comprehensive_evaluation(
    texto_largo,
    resultados[0]['summary'],
    "Mi Resumen",
    resultados[0],
    resultados[0]['selected_sentences']
)

print(f"ğŸ¯ Score General: {evaluacion['metrics']['overall_score']:.3f}")
print(f"ğŸ“ˆ ROUGE: {evaluacion['metrics']['rouge_like_score']:.3f}")
print(f"ğŸ”¤ BLEU: {evaluacion['metrics']['bleu_score']:.3f}")
```

### **3. PersonalizaciÃ³n para Dominios EspecÃ­ficos**

```python
class MedicalSummarizer(SemanticTFICFSummarizer):
    """Summarizer especializado en textos mÃ©dicos"""
    
    def __init__(self, n_sentences='auto'):
        super().__init__(n_sentences)
        self.medical_terms = {
            'diagnÃ³stico', 'tratamiento', 'sÃ­ntomas', 'paciente', 
            'enfermedad', 'medicamento', 'hospital', 'cÃ¡ncer'
        }
    
    def calculate_semantic_scores(self, processed_data):
        scores = super().calculate_semantic_scores(processed_data)
        
        # Bonus para tÃ©rminos mÃ©dicos
        for i, (idx, score, length) in enumerate(scores):
            sentence = processed_data['sentences'][idx].lower()
            medical_bonus = sum(1 for term in self.medical_terms if term in sentence)
            medical_bonus = min(medical_bonus * 0.15, 0.3)
            scores[i] = (idx, score * (1 + medical_bonus), length)
        
        return scores

# Pipeline mÃ©dico especializado
pipeline_medico = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor()),
    ('summarizer', MedicalSummarizer(n_sentences=4))
])
```

### **4. Procesamiento por Lotes**

```python
import pandas as pd

# Procesar mÃºltiples documentos
documentos = [texto1, texto2, texto3, texto4]
resultados = pipeline.fit_transform(documentos)

# Crear DataFrame con resultados
df_resultados = pd.DataFrame([{
    'resumen': r['summary'],
    'compresion': r['compression_ratio'],
    'idioma': r['language'],
    'oraciones_seleccionadas': len(r['selected_sentences'])
} for r in resultados])

df_resultados.to_csv('resumenes_generados.csv', index=False)
```

## ğŸ“Š **MÃ©tricas de EvaluaciÃ³n**

| MÃ©trica | DescripciÃ³n | Rango Ã“ptimo | InterpretaciÃ³n |
|---------|-------------|--------------|----------------|
| **ROUGE-like** | Cobertura de contenido | 0.4-0.7 | Mide quÃ© tan bien el resumen representa el contenido original |
| **BLEU Score** | Similitud lexical | 0.3-0.6 | EvalÃºa la similitud en tÃ©rminos especÃ­ficos con el original |
| **Coherencia** | Fluidez del resumen | 0.6-1.0 | Indica quÃ© tan bien fluyen las oraciones entre sÃ­ |
| **Cobertura** | Frases clave incluidas | 0.7-1.0 | Porcentaje de conceptos importantes capturados |
| **Diversidad** | Variedad lexical | 0.7-0.9 | Mide la riqueza vocabular del resumen |
| **Redundancia** | RepeticiÃ³n de tÃ©rminos | 0.0-0.2 | Menos es mejor - indica repeticiÃ³n excesiva |

## ğŸ¯ **TÃ©cnicas de IA Implementadas**

### **TF-ICF (Term Frequency - Inverse Class Frequency)**
Variante especializada de TF-IDF para resumen de documentos individuales. Trata cada oraciÃ³n como una "clase" y calcula la importancia de tÃ©rminos basÃ¡ndose en su distribuciÃ³n entre oraciones.

### **Clustering SemÃ¡ntico con K-means**
Agrupa oraciones similares usando representaciones vectoriales TF-IDF, permitiendo seleccionar oraciones diversas que cubran diferentes temas del documento.

### **AnÃ¡lisis de Frases Clave**
Identifica n-gramas importantes usando TF-IDF a nivel de documento completo, dando mayor peso a oraciones que contienen estos conceptos centrales.

### **Scoring Multi-dimensional**
Combina mÃºltiples seÃ±ales (posiciÃ³n, longitud, relevancia lÃ©xica, frases clave) con pesos aprendidos empÃ­ricamente para una selecciÃ³n balanceada.

## âš¡ **Rendimiento y OptimizaciÃ³n**

- **Procesamiento CPU**: Optimizado para funcionar sin GPUs
- **Dependencias mÃ­nimas**: Solo scikit-learn, numpy y NLTK bÃ¡sico
- **Escalabilidad**: Maneja documentos de 100 a 10,000 palabras
- **Tiempos de procesamiento**: ~1-5 segundos para documentos tÃ­picos

## ğŸ”§ **Configuraciones Recomendadas**

### **Para Noticias/ArtÃ­culos**
```python
pipeline_noticias = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor(min_word_length=2)),
    ('summarizer', SemanticTFICFSummarizer(n_sentences=3))
])
```

### **Para Documentos TÃ©cnicos**
```python
pipeline_tecnico = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor(min_word_length=4)),
    ('summarizer', SemanticTFICFSummarizer(n_sentences=4, diversity_weight=0.5))
])
```

### **Para Textos Muy Largos**
```python
pipeline_largo = Pipeline([
    ('preprocessor', EnhancedTextPreprocessor()),
    ('summarizer', SemanticTFICFSummarizer(n_sentences='auto'))
])
```

## ğŸ“ˆ **Resultados Esperados**

Con textos bien estructurados, el sistema tÃ­picamente produce:
- **CompresiÃ³n**: 20-30% del texto original
- **ROUGE Score**: 0.4-0.6
- **BLEU Score**: 0.3-0.5
- **Coherencia**: 0.6-0.8

## ğŸš¨ **Limitaciones y Consideraciones**

- Funciona mejor con textos bien estructurados y pÃ¡rrafos coherentes
- El rendimiento puede variar con textos muy tÃ©cnicos o especializados
- La detecciÃ³n de idioma asume textos mayoritariamente en un idioma
- Optimizado para espaÃ±ol e inglÃ©s, otros idiomas requieren ajustes

## ğŸ¤ **Contribuciones**

Las contribuciones son bienvenidas en Ã¡reas como:

- Soporte para mÃ¡s idiomas
- Mejoras en la detecciÃ³n de idioma
- Optimizaciones de rendimiento
- Nuevas mÃ©tricas de evaluaciÃ³n


# ğŸŒ **API REST - DocumentaciÃ³n Completa**

## ğŸš€ **InstalaciÃ³n y ConfiguraciÃ³n**

### **Requisitos**
```bash
pip install -r requirements.txt
```

### **Ejecutar el Servidor**
```bash
python main.py
```

La API estarÃ¡ disponible en: `http://localhost:8000`

### **DocumentaciÃ³n Interactiva**
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ“‹ **Endpoints Disponibles**

### **1. ğŸ©º Health Check**
Verifica el estado del servicio y disponibilidad.

**Endpoint**: `GET /api/v1/health`

**Respuesta**:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "model_ready": true,
  "timestamp": "2024-01-15 10:30:45"
}
```

**Ejemplo cURL**:
```bash
curl -X GET "http://localhost:8000/api/v1/health"
```

---

### **2. ğŸ“ Resumen de Texto Individual**
Genera un resumen extractivo de un texto individual.

**Endpoint**: `POST /api/v1/summarize`

**ParÃ¡metros de Entrada**:
```json
{
  "text": "La inteligencia artificial estÃ¡ transformando radicalmente el panorama tecnolÃ³gico global. Los avances en machine learning y deep learning han permitido desarrollar sistemas capaces de realizar tareas que antes se consideraban exclusivamente humanas...",
  "n_sentences": 3,
  "language": "auto",
  "include_metrics": true
}
```

**ParÃ¡metros**:
- `text` (string, requerido): Texto a resumir (mÃ­nimo 100 caracteres)
- `n_sentences` (int, opcional): NÃºmero de oraciones en el resumen. `auto` para cÃ¡lculo automÃ¡tico
- `language` (string, opcional): Idioma del texto. `auto` para detecciÃ³n automÃ¡tica
- `include_metrics` (boolean, opcional): Incluir mÃ©tricas de evaluaciÃ³n (default: true)

**Respuesta Exitosa**:
```json
{
  "summary": "La inteligencia artificial transforma el panorama tecnolÃ³gico. Los avances en machine learning permiten sistemas capaces de tareas humanas. Esto impacta diversos sectores como medicina y educaciÃ³n.",
  "original_length": 1250,
  "summary_length": 180,
  "compression_ratio": 0.144,
  "language": "es",
  "selected_sentences": [0, 2, 5],
  "processing_time": 1.23,
  "metrics": {
    "rouge_like_score": 0.65,
    "bleu_score": 0.45,
    "coherence": 0.78,
    "overall_score": 0.72
  },
  "key_phrases": [
    "inteligencia artificial",
    "machine learning", 
    "deep learning",
    "procesamiento lenguaje natural"
  ]
}
```

**Ejemplo cURL**:
```bash
curl -X POST "http://localhost:8000/api/v1/summarize" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Tu texto largo aquÃ­...",
       "n_sentences": 3,
       "include_metrics": true
     }'
```

---

### **3. ğŸ“š Procesamiento por Lotes**
Genera resÃºmenes para mÃºltiples textos en una sola solicitud.

**Endpoint**: `POST /api/v1/summarize/batch`

**ParÃ¡metros de Entrada**:
```json
{
  "texts": [
    "Primer texto largo para resumir...",
    "Segundo texto largo para resumir...",
    "Tercer texto largo para resumir..."
  ],
  "n_sentences": 3,
  "include_metrics": false
}
```

**ParÃ¡metros**:
- `texts` (array, requerido): Lista de textos a resumir (mÃ­nimo 1 texto)
- `n_sentences` (int, opcional): NÃºmero de oraciones por resumen (default: 3)
- `include_metrics` (boolean, opcional): Incluir mÃ©tricas para cada texto (default: false)

**Respuesta Exitosa**:
```json
{
  "summaries": [
    {
      "summary": "Resumen del primer texto...",
      "original_length": 800,
      "summary_length": 150,
      "compression_ratio": 0.187,
      "language": "es",
      "selected_sentences": [0, 2, 4],
      "processing_time": 0.0
    },
    {
      "summary": "Resumen del segundo texto...",
      "original_length": 1200,
      "summary_length": 200,
      "compression_ratio": 0.166,
      "language": "es", 
      "selected_sentences": [1, 3, 5],
      "processing_time": 0.0
    }
  ],
  "total_processed": 2,
  "average_compression": 0.176,
  "total_processing_time": 2.45
}
```

**Ejemplo cURL**:
```bash
curl -X POST "http://localhost:8000/api/v1/summarize/batch" \
     -H "Content-Type: application/json" \
     -d '{
       "texts": ["texto1...", "texto2...", "texto3..."],
       "n_sentences": 2,
       "include_metrics": true
     }'
```

---

### **4. ğŸ“Š ComparaciÃ³n de ResÃºmenes**
EvalÃºa la calidad de un resumen comparÃ¡ndolo con el texto original.

**Endpoint**: `GET /api/v1/metrics/compare`

**ParÃ¡metros Query**:
- `original` (string, requerido): Texto original
- `summary` (string, requerido): Texto resumen a evaluar

**Respuesta Exitosa**:
```json
{
  "comparison_metrics": {
    "rouge_like_score": 0.72,
    "bleu_score": 0.51,
    "coherence": 0.85,
    "overall_score": 0.76
  },
  "details": {
    "original_length": 1500,
    "summary_length": 240,
    "compression_ratio": 0.16,
    "key_phrases_coverage": 0.8,
    "coherence_score": 0.85
  },
  "quality_assessment": {
    "quality_level": "BUENA",
    "overall_score": 0.76,
    "issues": ["PodrÃ­a mejorar la cobertura de contenido"],
    "recommendations": ["Incluir mÃ¡s oraciones clave del texto original"]
  }
}
```

**Ejemplo cURL**:
```bash
curl -X GET "http://localhost:8000/api/v1/metrics/compare?original=TextoOriginal...&summary=ResumenGenerado..."
```

---

### **5. âš™ï¸ ConfiguraciÃ³n del Pipeline**
Actualiza parÃ¡metros del pipeline en tiempo de ejecuciÃ³n.

**Endpoint**: `PUT /api/v1/config`

**ParÃ¡metros Query**:
- `n_sentences` (int, opcional): NÃºmero de oraciones para resÃºmenes (1-20)
- `min_word_length` (int, opcional): Longitud mÃ­nima de palabras (2-10)
- `diversity_weight` (float, opcional): Peso para diversidad en scoring (0.0-1.0)

**Respuesta Exitosa**:
```json
{
  "updated_parameters": {
    "n_sentences": 4,
    "min_word_length": 3
  },
  "status": "success"
}
```

**Ejemplo cURL**:
```bash
curl -X PUT "http://localhost:8000/api/v1/config?n_sentences=4&min_word_length=3"
```

---

### **6. ğŸ“ˆ MÃ©tricas del Servicio**
Obtiene estadÃ­sticas de uso y rendimiento del servicio.

**Endpoint**: `GET /api/v1/metrics/service`

**Respuesta Exitosa**:
```json
{
  "service_uptime": "2h 30m",
  "total_summaries_generated": "N/A",
  "average_processing_time": "N/A", 
  "memory_usage": "N/A"
}
```

**Ejemplo cURL**:
```bash
curl -X GET "http://localhost:8000/api/v1/metrics/service"
```

---

## ğŸ”§ **Ejemplos de Uso en Diferentes Lenguajes**

### **Python**
```python
import requests
import json

# Configurar la URL base
BASE_URL = "http://localhost:8000/api/v1"

# Ejemplo 1: Resumen individual
def resumen_individual(texto):
    payload = {
        "text": texto,
        "n_sentences": 3,
        "include_metrics": True
    }
    
    response = requests.post(f"{BASE_URL}/summarize", json=payload)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error: {response.status_code}")
        return None

# Ejemplo 2: Procesamiento por lotes
def resumen_lotes(textos):
    payload = {
        "texts": textos,
        "n_sentences": 2,
        "include_metrics": False
    }
    
    response = requests.post(f"{BASE_URL}/summarize/batch", json=payload)
    return response.json()

# Ejemplo de uso
texto_largo = "Tu texto muy largo aquÃ­..."
resultado = resumen_individual(texto_largo)
print(f"Resumen: {resultado['summary']}")
print(f"CompresiÃ³n: {resultado['compression_ratio']:.1%}")
```

### **JavaScript**
```javascript
// Ejemplo con fetch API
async function generarResumen(texto) {
    const response = await fetch('http://localhost:8000/api/v1/summarize', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            text: texto,
            n_sentences: 3,
            include_metrics: true
        })
    });
    
    const data = await response.json();
    return data;
}

// Uso
const texto = "Texto largo para resumir...";
generarResumen(texto)
    .then(resultado => {
        console.log('Resumen:', resultado.summary);
        console.log('MÃ©tricas:', resultado.metrics);
    })
    .catch(error => console.error('Error:', error));
```

### **cURL Avanzado**
```bash
# Resumen con texto desde archivo
curl -X POST "http://localhost:8000/api/v1/summarize" \
     -H "Content-Type: application/json" \
     -d "$(jq -n --arg text "$(cat documento.txt)" '{
       text: $text,
       n_sentences: 4,
       include_metrics: true
     }')"

# Batch processing desde archivo JSON
curl -X POST "http://localhost:8000/api/v1/summarize/batch" \
     -H "Content-Type: application/json" \
     -d @batch_request.json
```

---

## ğŸš¨ **Manejo de Errores**

### **CÃ³digos de Estado HTTP**
- `200 OK`: Solicitud exitosa
- `400 Bad Request`: ParÃ¡metros invÃ¡lidos o texto muy corto
- `500 Internal Server Error`: Error interno del servidor

### **Respuesta de Error**:
```json
{
  "error": "El texto debe tener al menos 100 caracteres",
  "details": {
    "text_length": 45
  },
  "code": 400
}
```

### **Errores Comunes**:
- **Texto muy corto**: El texto debe tener al menos 100 caracteres
- **Texto vacÃ­o**: El texto no puede estar vacÃ­o
- **Insuficientes oraciones**: El texto debe contener al menos 2 oraciones significativas
- **ParÃ¡metros invÃ¡lidos**: Valores fuera de rangos permitidos

---

## âš¡ **Mejores PrÃ¡cticas**

### **1. OptimizaciÃ³n de Rendimiento**
```python
# Para textos largos (>5000 palabras)
payload = {
    "text": texto_largo,
    "n_sentences": "auto",  # CÃ¡lculo automÃ¡tico Ã³ptimo
    "include_metrics": False  # Desactivar mÃ©tricas para mayor velocidad
}
```

### **2. Procesamiento por Lotes Eficiente**
```python
# Agrupar textos similares en tamaÃ±o
textos_cortos = [t for t in textos if len(t) < 1000]
textos_largos = [t for t in textos if len(t) >= 1000]

# Procesar por lotes separados
resultados_cortos = resumen_lotes(textos_cortos)
resultados_largos = resumen_lotes(textos_largos)
```

### **3. Manejo de Timeouts**
```python
import requests

# Configurar timeout
try:
    response = requests.post(
        "http://localhost:8000/api/v1/summarize", 
        json=payload, 
        timeout=30  # 30 segundos timeout
    )
except requests.exceptions.Timeout:
    print("La solicitud tardÃ³ demasiado tiempo")
```


## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT.